{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45837,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":38432}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport urllib.request\nimport zipfile\nimport imageio","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-09T19:19:19.025103Z","iopub.execute_input":"2024-05-09T19:19:19.025498Z","iopub.status.idle":"2024-05-09T19:19:19.030225Z","shell.execute_reply.started":"2024-05-09T19:19:19.025446Z","shell.execute_reply":"2024-05-09T19:19:19.029194Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def load_tiny_imagenet_data(data_dir=\"tiny-imagenet-200\"):\n    # Download and extract Tiny ImageNet dataset if not already downloaded\n    if not os.path.exists(data_dir):\n        print(\"Downloading Tiny ImageNet dataset...\")\n        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n        urllib.request.urlretrieve(url, \"tiny-imagenet-200.zip\")\n        with zipfile.ZipFile(\"tiny-imagenet-200.zip\", \"r\") as zip_ref:\n            zip_ref.extractall()\n\n    # Load training data\n    train_images = []\n    train_labels = []\n    train_dir = os.path.join(data_dir, \"train\")\n    for subdir in os.listdir(train_dir):\n        subdir_path = os.path.join(train_dir, subdir)\n        if os.path.isdir(subdir_path):\n            for img_file in os.listdir(subdir_path + \"/images\"):\n                img_path = os.path.join(subdir_path + \"/images\", img_file)\n                img = imageio.imread(img_path)\n                train_images.append(img)\n                train_labels.append(subdir)\n\n    # Load validation data\n    test_images = []\n    test_labels = []\n    with open(os.path.join(data_dir, \"val\", \"val_annotations.txt\"), \"r\") as file:\n        for line in file:\n            img_file, label, _, _, _, _ = line.split(\"\\t\")\n            img_path = os.path.join(data_dir, \"val\", \"images\", img_file)\n            img = imageio.imread(img_path)\n            test_images.append(img)\n            test_labels.append(label)\n\n    # Convert lists to numpy arrays\n    train_images = np.array(train_images)\n    train_labels = np.array(train_labels)\n    test_images = np.array(test_images)\n    test_labels = np.array(test_labels)\n\n    return train_images, train_labels, test_images, test_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:19:29.275006Z","iopub.execute_input":"2024-05-09T19:19:29.275386Z","iopub.status.idle":"2024-05-09T19:19:29.286096Z","shell.execute_reply.started":"2024-05-09T19:19:29.275360Z","shell.execute_reply":"2024-05-09T19:19:29.285175Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport urllib.request\nimport zipfile\nfrom PIL import Image\n\ndef load_tiny_imagenet_data(data_dir=\"tiny-imagenet-200\", target_size=(64, 64)):\n    # Download and extract Tiny ImageNet dataset if not already downloaded\n    if not os.path.exists(data_dir):\n        print(\"Downloading Tiny ImageNet dataset...\")\n        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n        urllib.request.urlretrieve(url, \"tiny-imagenet-200.zip\")\n        with zipfile.ZipFile(\"tiny-imagenet-200.zip\", \"r\") as zip_ref:\n            zip_ref.extractall()\n\n    # Load training data\n    train_images = []\n    train_labels = []\n    train_dir = os.path.join(data_dir, \"train\")\n    for subdir in os.listdir(train_dir):\n        subdir_path = os.path.join(train_dir, subdir)\n        if os.path.isdir(subdir_path):\n            for img_file in os.listdir(subdir_path + \"/images\"):\n                img_path = os.path.join(subdir_path + \"/images\", img_file)\n                #img = Image.open(img_path)\n                img = img.resize(target_size)  # Resize the image to the target size\n                img = np.array(img)\n                train_images.append(img)\n                train_labels.append(subdir)\n\n    # Load validation data\n    test_images = []\n    test_labels = []\n    with open(os.path.join(data_dir, \"val\", \"val_annotations.txt\"), \"r\") as file:\n        for line in file:\n            img_file, label, _, _, _, _ = line.split(\"\\t\")\n            img_path = os.path.join(data_dir, \"val\", \"images\", img_file)\n            img = Image.open(img_path)\n            #img = img.resize(target_size)  # Resize the image to the target size\n            img = np.array(img)\n            test_images.append(img)\n            test_labels.append(label)\n\n    # Convert lists to numpy arrays\n    train_images = np.array(train_images)\n    train_labels = np.array(train_labels)\n    test_images = np.array(test_images)\n    test_labels = np.array(test_labels)\n\n    return train_images, train_labels, test_images, test_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:43:17.887157Z","iopub.execute_input":"2024-05-09T19:43:17.887550Z","iopub.status.idle":"2024-05-09T19:43:17.899935Z","shell.execute_reply.started":"2024-05-09T19:43:17.887523Z","shell.execute_reply":"2024-05-09T19:43:17.898977Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Resize the images to match the input shape of the model\ndef resize_images(images):\n    resized_images = tf.image.resize(images, (32, 32))\n    return resized_images\n\n# Load Tiny ImageNet data\n# Assuming you have a function load_tiny_imagenet_data() to load the data\ntrain_images, train_labels, test_images, test_labels = load_tiny_imagenet_data()\n\n# Preprocess the data and resize the images\ntrain_images = resize_images(train_images)\ntest_images = resize_images(test_images)\n\n# Data Augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\ndatagen.fit(train_images)\n\n# Load the custom model from Experiment 1\n# Assuming you have already defined and trained the model\ncustom_model = model.load(r'/kaggle/input/mycustom/keras/myvalslug/1/cifar.keras')\n\n# Adjust the output layer for 200 classes\ncustom_model.layers[-1].units = 200\ncustom_model.layers[-1].activation = 'softmax'\n\n# Unfreeze the base model (VGG19)\ncustom_model.trainable = True\ncustom_model.layers[0].trainable = True  # Assuming the base model is the first layer\n\n# Rebuild the model after changing trainable status\ncustom_model.build((None, 32, 32, 3))\n\n# Define the optimizer with learning rate scheduler\ninitial_learning_rate = 0.001  # Adjust as needed\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.9,\n    staircase=True\n)\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n# Compile the model with the defined optimizer\ncustom_model.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nhistory = custom_model.fit(\n    datagen.flow(train_images, train_labels, batch_size=64),\n    steps_per_epoch=len(train_images) // 64,\n    epochs=10,  # Adjust as needed\n    validation_data=(test_images, test_labels)\n)\n\n# Report the final training and testing accuracy\nfinal_train_acc = history.history['accuracy'][-1]\nfinal_test_acc = custom_model.evaluate(test_images, test_labels, verbose=0)[1]\n\nprint(\"Final Training Accuracy:\", final_train_acc)\nprint(\"Final Testing Accuracy:\", final_test_acc)\n\n#Optionally, you can save the model and history for further analysis\ncustom_model.save(\"custom_model_tiny_imagenet.h5\")\nnp.save(\"history.npy\", history.history)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:43:20.860619Z","iopub.execute_input":"2024-05-09T19:43:20.861482Z","iopub.status.idle":"2024-05-09T19:43:46.471975Z","shell.execute_reply.started":"2024-05-09T19:43:20.861454Z","shell.execute_reply":"2024-05-09T19:43:46.470664Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized_images\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load Tiny ImageNet data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Assuming you have a function load_tiny_imagenet_data() to load the data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_images, train_labels, test_images, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_tiny_imagenet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Preprocess the data and resize the images\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_images \u001b[38;5;241m=\u001b[39m resize_images(train_images)\n","Cell \u001b[0;32mIn[32], line 45\u001b[0m, in \u001b[0;36mload_tiny_imagenet_data\u001b[0;34m(data_dir, target_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         test_labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convert lists to numpy arrays\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_labels)\n\u001b[1;32m     47\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_images)\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (100000, 64, 64) + inhomogeneous part."],"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (100000, 64, 64) + inhomogeneous part.","output_type":"error"}]}]}